name: Train random forest model using scikit learn from CSV
description: Train random forest model using Scikit-learn
metadata:
  annotations: {author: Alexey Volkov <alexey.volkov@ark-kun.com>, canonical_location: 'https://raw.githubusercontent.com/Ark-kun/pipeline_components/master/components/ML_frameworks/Scikit_learn/Train_logistic_regression_model/from_CSV/component.yaml'}
inputs:
- {name: dataset, type: CSV}
- {name: label_column_name, type: String}
- {name: random_seed, type: Integer, default: '0', optional: true}
- {name: n_estimators, type: Integer, default: 20, optional: true}
- {name: max_leaf_nodes, type: Integer, default: 2, optional: true}
- {name: max_depth, type: Integer, default: 2, optional: true}
- {name: criterion, type: String, default: 'gini', optional: true}

outputs:
- {name: model, type: ScikitLearnPickleModel}
- {name: model_parameters, type: JsonObject}
implementation:
  container:
    image: python:3.9
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'scikit-learn==1.0.2' 'pandas==1.4.3' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3
      -m pip install --quiet --no-warn-script-location 'scikit-learn==1.0.2' 'pandas==1.4.3'
      --user) && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - |
      def _make_parent_dirs_and_return_path(file_path: str):
          import os
          os.makedirs(os.path.dirname(file_path), exist_ok=True)
          return file_path

      def train_random_forest_model_using_scikit_learn_from_CSV(
          dataset_path,
          model_path,
          label_column_name,
          n_estimators = 20,
          max_leaf_nodes = 2,
          max_depth = 2,
          criterion = "gini",
          random_seed = 0,
      ):
          
          import json
          import pandas
          import pickle
          from sklearn import ensemble

          df = pandas.read_csv(dataset_path)
          model = ensemble.LogisticRegression(
              n_estimators=n_estimators,
              max_depth=max_depth,
              criterion=criterion,
              max_leaf_nodes=max_leaf_nodes,
              verbose=1,
              random_state=random_seed,
          )

          model_parameters = model.get_params()
          model_parameters_json = json.dumps(model_parameters, indent=2)
          print("Model parameters:")
          print(model_parameters_json)
          print()

          model.fit(
              X=df.drop(columns=label_column_name),
              y=df[label_column_name],
          )

          with open(model_path, "wb") as f:
              pickle.dump(model, f)

          return (model_parameters_json,)

      def _serialize_json(obj) -> str:
          if isinstance(obj, str):
              return obj
          import json
          def default_serializer(obj):
              if hasattr(obj, 'to_struct'):
                  return obj.to_struct()
              else:
                  raise TypeError("Object of type '%s' is not JSON serializable and does not have .to_struct() method." % obj.__class__.__name__)
          return json.dumps(obj, default=default_serializer, sort_keys=True)

      import argparse
      _parser = argparse.ArgumentParser(prog='Train random forest model using scikit learn from CSV', description='Train random forest model using Scikit-learn')
      _parser.add_argument("--dataset", dest="dataset_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--label-column-name", dest="label_column_name", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--n-estimators", dest="n_estimators", type=int, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--max-depth", dest="max_depth", type=int, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--criterion", dest="criterion", type=str, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--max-leaf-nodes", dest="max_leaf_nodes", type=int, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--random-seed", dest="random_seed", type=int, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--model", dest="model_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
      _parsed_args = vars(_parser.parse_args())
      _output_files = _parsed_args.pop("_output_paths", [])

      _outputs = train_random_forest_model_using_scikit_learn_from_CSV(**_parsed_args)

      _output_serializers = [
          _serialize_json,

      ]

      import os
      for idx, output_file in enumerate(_output_files):
          try:
              os.makedirs(os.path.dirname(output_file))
          except OSError:
              pass
          with open(output_file, 'w') as f:
              f.write(_output_serializers[idx](_outputs[idx]))
    args:
    - --dataset
    - {inputPath: dataset}
    - --label-column-name
    - {inputValue: label_column_name}
    - if:
        cond: {isPresent: n_estimators}
        then:
        - --n-estimators
        - {inputValue: n_estimators}
    - if:
        cond: {isPresent: max_depth}
        then:
        - --max-depth
        - {inputValue: max_depth}
    - if:
        cond: {isPresent: criterion}
        then:
        - --criterion
        - {inputValue: criterion}
    - if:
        cond: {isPresent: max_leaf_nodes}
        then:
        - --max-leaf-nodes
        - {inputValue: max_leaf_nodes}
    - if:
        cond: {isPresent: random_seed}
        then:
        - --random-seed
        - {inputValue: random_seed}
    - --model
    - {outputPath: model}
    - '----output-paths'
    - {outputPath: model_parameters}