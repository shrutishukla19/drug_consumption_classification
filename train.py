# -*- coding: utf-8 -*-
"""train2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K4Y1rsNiq-wrbIOkeFCyTLRFYbmEGWlC
"""

import os, joblib, logging, argparse
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.multioutput import MultiOutputClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from google.cloud import storage

logging.basicConfig(level=logging.INFO)
parser = argparse.ArgumentParser()

#Input Arguments
parser.add_argument(
    '--data_gcs_path',
    help = 'Dataset file on Google Cloud Storage',
    type = str
)

parser.add_argument(
    '--model_dir',
    help = 'Directory to output model artificats',
    type = str,
    default = os.environ['AIP_MODEL_DIR'] if 'AIP_MODEL_DIR' in os.environ else ""
)

#Parse arguments
args = parser.parse_args()
arguments = args._dict_

#Get dataset from GCS

data_gcs_path = arguments['data_gcs_path']
df = pd.read_csv(data_gcs_path)
logging.info("reading gs data: {}".format(data_gcs_path))

#label encoding
columns = ['Alcohol','Amphet', 'Amyl', 'Benzos', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack',
          'Ecstasy', 'Heroin', 'Ketamine', 'Legalh', 'LSD', 'Meth', 'Mushrooms','Nicotine', 'Semer', 'VSA']

for column in columns:
  le = LabelEncoder()
  df[column] = le.fit_transform(df[column])

#split data into feature and target
X = df.drop(columns = columns)
y = df[columns]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Random Forest Classifier
# Create an instance of RandomForestClassifier
base_classifier = RandomForestClassifier()

# Create an instance of MultiOutputClassifier with base_classifier
model = MultiOutputClassifier(base_classifier, n_jobs=-1)

# Fit the model
model.fit(X_train, y_train)

# Score the model
score = model.score(X_test, y_test)
preds = model.predict(X_test)

print("Score: " ,score)
print("Predictions: " ,preds)

# Iterate over each label and print classification report
for i, target_label in enumerate(y_test.columns):
    print(f"Classification Report for RandomForestClassifier - {target_label}:")
    report = classification_report(y_test.iloc[:, i], preds[:, i])
    print(report)
    logging.info("Classification Report for RandomForestClassifier - {}:".format(taget_label))
    logging.info(report)

artifact_filename = 'model.joblib'

# save model artifact to local filesystem
local_path = artifact_filename
joblib.dump(model, local_path)

# Upload model artifact to cloud storage
model_directory = arguments['model_dir']
if model_directory == "":
  print("Training is run locally - skipping model saving to GCS.")
else:
  storage_path = os.path.join(model_directory, artifact_filename)
  blob = storage.blob.Blob.from_string(storage_path, client=storage.Client())
  blob.upload_from_filename(local_path)
  logging.info("modelexported to : {}".format(storage_path))